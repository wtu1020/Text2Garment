pretrained_vae_path: 'ckpt/pretrained_weights/vae'
pretrained_unet_path: 'ckpt/pretrained_weights/unet'
pretrained_motion_module_path: 'ckpt/pretrained_weights/motion_module.ckpt'
ckpt_path: 'ckpt/Text2Garment_base'
num_views: 20

weight_dtype: 'fp16'
unet_attention_mode: "read_concat_attn"  # ["read_concat_attn", "read_cross_attn"] 
use_clip_cross_attention: false
camera_use_radius: false

noise_scheduler_kwargs:
  beta_start: 0.00085
  beta_end: 0.012
  beta_schedule: "linear"
  clip_sample: false
  steps_offset: 1
  prediction_type: "v_prediction"
  rescale_betas_zero_snr: True
  timestep_spacing: "trailing"

pose_guider_kwargs:
  conditioning_embedding_channels: 320
  conditioning_channels: 3
  block_out_channels: [16, 32, 96, 256]
  use_guidance_attention: False
  attention_num_heads: 8

unet_additional_kwargs:
  use_motion_module: true
  unet_use_temporal_attention: false
  use_camera_embedding: true
  camera_dim: 9
  use_clip_cross_attention: false
  down_block_attention_indices: [[0,36,324],[0,54,306],[0,72,288],[]]
  mid_block_attention_index: [0,90,270]
  up_block_attention_indices: [[],[0,72,288],[0,54,306],[0,36,324]]
  branch_num: 1
  copy_first_n_block: 1
  copy_last_n_block: 1
  fusion: "avg"
  use_inflated_groupnorm: true
  unet_use_cross_frame_attention: false 
  motion_module_resolutions: [1, 2, 4, 8]
  motion_module_mid_block: true 
  motion_module_decoder_only: false
  motion_module_type: Vanilla
  motion_module_kwargs:
    num_attention_heads: 8
    num_transformer_block: 1
    attention_block_types:
    - Temporal_Self
    - Temporal_Self
    temporal_position_encoding: true
    temporal_position_encoding_max_len: ${num_views}
    temporal_position_encoding_type: RPE
    temporal_attention_dim_div: 1

hps_type: pymafx
patience: 5
cfg_scale: 2.5
guidance_rescale: 0.7
smplx_guidance_scales: [2.5] 
iterative_optimization_steps: [40]
intermediate_denoising_steps: 20
final_denoising_steps: 25
use_normal_loss: false
            

